{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random as rd\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from model import LPGNN\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_random_linear_program(num_variables, num_constraints, nnz = 5):\n",
    "    # Generate random coefficients for the objective function\n",
    "    c = np.random.uniform(-1, 1, num_variables) * 0.01\n",
    "\n",
    "    # Generate random coefficients for the constraint matrix\n",
    "    A = np.zeros((num_constraints, num_variables))\n",
    "    EdgeIndex = np.zeros((nnz, 2))\n",
    "    EdgeIndex1D = rd.sample(range(num_constraints * num_variables), nnz)\n",
    "    EdgeFeature = np.random.normal(0, 1, nnz)\n",
    "        \n",
    "    for l in range(nnz):\n",
    "        i = int(EdgeIndex1D[l] / num_variables)\n",
    "        j = EdgeIndex1D[l] - i * num_variables\n",
    "        EdgeIndex[l, 0] = i\n",
    "        EdgeIndex[l, 1] = j\n",
    "        A[i, j] = EdgeFeature[l]\n",
    "\n",
    "    # Generate random right-hand side values for the constraints\n",
    "    b = np.random.uniform(-1, 1, num_constraints)\n",
    "\n",
    "    bounds = np.random.normal(0, 10, size = (num_variables, 2))\n",
    "        \n",
    "    for j in range(num_variables):\n",
    "        if bounds[j, 0] > bounds[j, 1]:\n",
    "            temp = bounds[j, 0]\n",
    "            bounds[j, 0] = bounds[j, 1]\n",
    "            bounds[j, 1] = temp\n",
    "\n",
    "    # Generate random constraint types (0 for <= and 1 for =)\n",
    "    constraint_types = np.random.choice([0, 1], size=num_constraints, p=[0.7, 0.3])\n",
    "\n",
    "    # Adjust the constraint matrix and right-hand side based on the constraint types\n",
    "    for i in range(num_constraints):\n",
    "        if constraint_types[i] == 1:  # Equality constraint\n",
    "            b[i] = np.dot(A[i], np.random.rand(num_variables))  # Randomly generate a feasible solution\n",
    "\n",
    "    # Return the generated linear program\n",
    "    return c, A, b, constraint_types, bounds\n",
    "\n",
    "\n",
    "def solve_linear_program(c, A, b, constraint_types, bounds):\n",
    "    # Solve the linear program\n",
    "    res = linprog(c, A_ub=A[constraint_types == 0], b_ub=b[constraint_types == 0],\n",
    "                  A_eq=A[constraint_types == 1], b_eq=b[constraint_types == 1], bounds=bounds)\n",
    "\n",
    "    # Return the solution\n",
    "    return res.x, res.status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_and_solve_batches(num_batches, num_variables, num_constraints, out_func):\n",
    "    batches_c = []\n",
    "    batches_A = []\n",
    "    batches_b = []\n",
    "    batches_constraint_types = []\n",
    "    batches_lower_bounds = []\n",
    "    batches_upper_bounds = []\n",
    "    batches_solutions = []\n",
    "    batches_feasibility = []\n",
    "    \n",
    "    if out_func == 'feas':\n",
    "        for _ in range(num_batches):\n",
    "            c, A, b, constraint_types, bounds = generate_random_linear_program(num_variables,\n",
    "                                                                               num_constraints)\n",
    "\n",
    "            solution, feasibility = solve_linear_program(c, A, b, constraint_types, bounds)\n",
    "\n",
    "            lower_bounds, upper_bounds = zip(*bounds)\n",
    "\n",
    "            batches_c.append(torch.tensor(c, dtype=torch.float32))\n",
    "            batches_A.append(torch.tensor(A, dtype=torch.float32))\n",
    "            batches_b.append(torch.tensor(b, dtype=torch.float32))\n",
    "            batches_constraint_types.append(torch.tensor(constraint_types, dtype=torch.float32))\n",
    "            batches_lower_bounds.append(torch.tensor(lower_bounds, dtype=torch.float32))\n",
    "            batches_upper_bounds.append(torch.tensor(upper_bounds, dtype=torch.float32))\n",
    "\n",
    "            if type(solution) != type(None):\n",
    "                batches_solutions.append(torch.tensor(solution, dtype=torch.float32))\n",
    "\n",
    "            else:\n",
    "                batches_solutions.append(torch.zeros(num_variables, dtype=torch.float32))\n",
    "\n",
    "            batches_feasibility.append(torch.tensor(1 if feasibility != 2 else 0, dtype=torch.float32))\n",
    "\n",
    "        return (\n",
    "            torch.stack(batches_c),\n",
    "            torch.stack(batches_A),\n",
    "            torch.stack(batches_b),\n",
    "            torch.stack(batches_constraint_types),\n",
    "            torch.stack(batches_lower_bounds),\n",
    "            torch.stack(batches_upper_bounds),\n",
    "            torch.stack(batches_solutions),\n",
    "            torch.stack(batches_feasibility)\n",
    "        )\n",
    "    else:\n",
    "        while len(batches_c) != num_batches:\n",
    "            c, A, b, constraint_types, bounds = generate_random_linear_program(num_variables,\n",
    "                                                                               num_constraints)\n",
    "            solution, feasibility = solve_linear_program(c, A, b, constraint_types, bounds)\n",
    "\n",
    "            if (type(solution) == type(None)):\n",
    "                continue\n",
    "            \n",
    "            lower_bounds, upper_bounds = zip(*bounds)\n",
    "\n",
    "            batches_c.append(torch.tensor(c, dtype=torch.float32))\n",
    "            batches_A.append(torch.tensor(A, dtype=torch.float32))\n",
    "            batches_b.append(torch.tensor(b, dtype=torch.float32))\n",
    "            batches_constraint_types.append(torch.tensor(constraint_types, dtype=torch.float32))\n",
    "            batches_lower_bounds.append(torch.tensor(lower_bounds, dtype=torch.float32))\n",
    "            batches_upper_bounds.append(torch.tensor(upper_bounds, dtype=torch.float32))\n",
    "            batches_solutions.append(torch.tensor(solution, dtype=torch.float32))\n",
    "            batches_feasibility.append(torch.tensor(1 if feasibility != 2 else 0, dtype=torch.float32))\n",
    "\n",
    "        return (\n",
    "            torch.stack(batches_c),\n",
    "            torch.stack(batches_A),\n",
    "            torch.stack(batches_b),\n",
    "            torch.stack(batches_constraint_types),\n",
    "            torch.stack(batches_lower_bounds),\n",
    "            torch.stack(batches_upper_bounds),\n",
    "            torch.stack(batches_solutions),\n",
    "            torch.stack(batches_feasibility)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS ###\n",
    "num_constraints = 2\n",
    "num_variables = 5\n",
    "batch_size = 10\n",
    "N = 100\n",
    "out_func = 'obj'\n",
    "\n",
    "device = device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = LPGNN(num_constraints, num_variables).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 200\n",
    "pbar = tqdm(range(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = []\n",
    "for i in range(N):\n",
    "    c, A, b, constraints, l, u, solution, feasibility = generate_and_solve_batches(batch_size,\n",
    "                                                                                   num_variables,\n",
    "                                                                                   num_constraints,\n",
    "                                                                                   out_func)\n",
    "    data_train.append([c, A, b, constraints, l, u, solution, feasibility])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, c, A, b, constraint, l, u, sol, feas, out_func, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(c, A, b, constraint, l, u, out_func)\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    if out_func == 'feas':\n",
    "        loss = loss(out, feas)\n",
    "\n",
    "    elif out_func == 'obj':\n",
    "        #loss = loss(out, (c[:, None, :] @ sol[:, :, None])[:,0])\n",
    "        loss = loss(out[:,0], torch.sum(c * sol, dim=1))\n",
    "\n",
    "    else:\n",
    "        loss = loss(out, sol)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training model\n",
    "print(\"\\n\\n\")\n",
    "print(\"Training model\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    for batch in data_train:\n",
    "        c, A, b, constraints, l, u, sol, feas = batch\n",
    "        c = c.to(device)\n",
    "        A = A.to(device)\n",
    "        b = b.to(device)\n",
    "        constraints = constraints.to(device)\n",
    "        l = l.to(device)\n",
    "        u = u.to(device)\n",
    "        sol = sol.to(device)\n",
    "        feas = feas\n",
    "        loss = train(model, c, A, b, constraints, l, u, sol, feas, out_func, optimizer)\n",
    "        pbar.set_description(f\"%.8f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "print(\"\\n\\n\")\n",
    "print(\"Testing model\")\n",
    "print(\"\\n\\n\")\n",
    "batch_size = 5\n",
    "M = 10\n",
    "\n",
    "data_test = []\n",
    "for i in range(M):\n",
    "    c, A, b, constraints, l, u, solution, feasibility = generate_and_solve_batches(batch_size,\n",
    "                                                                                   num_variables,\n",
    "                                                                                   num_constraints,\n",
    "                                                                                   out_func)\n",
    "    data_test.append([c, A, b, constraints, l, u, solution, feasibility])\n",
    "\n",
    "def test(model, c, A, b, constraint, l, u, sol, feas, out_func):\n",
    "    out = model.forward(c, A, b, constraint, l, u, out_func)\n",
    "    loss = nn.MSELoss()\n",
    "    if out_func == 'feas':\n",
    "        loss = loss(out, feas)\n",
    "    elif out_func == 'obj':\n",
    "        loss = loss(out, c.T @ sol)\n",
    "    else:\n",
    "        loss = loss(out, sol)\n",
    "    return loss\n",
    "\n",
    "\n",
    "for batch in data_test:\n",
    "    c, A, b, constraints, l, u, sol, feas = batch\n",
    "    c = c.to(device)\n",
    "    A = A.to(device)\n",
    "    b = b.to(device)\n",
    "    constraints = constraints.to(device)\n",
    "    l = l.to(device)\n",
    "    u = u.to(device)\n",
    "    sol = sol.to(device)\n",
    "    feas = feas.to(device)\n",
    "\n",
    "    loss = test(model, c, A, b, constraints, l, u, sol, feas, out_func)\n",
    "    print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = LPGNN(num_constraints, num_variables).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# Test model\n",
    "print(\"\\n\\n\")\n",
    "print(\"Testing model\")\n",
    "print(\"\\n\\n\")\n",
    "batch_size = 5\n",
    "M = 10\n",
    "\n",
    "data_test = []\n",
    "for i in range(M):\n",
    "    c, A, b, constraints, l, u, solution, feasibility = generate_and_solve_batches(batch_size,\n",
    "                                                                                   num_variables,\n",
    "                                                                                   num_constraints,\n",
    "                                                                                   out_func)\n",
    "    data_test.append([c, A, b, constraints, l, u, solution, feasibility])\n",
    "\n",
    "def test(model, c, A, b, constraint, l, u, sol, feas, out_func):\n",
    "    out = model.forward(c, A, b, constraint, l, u, out_func)\n",
    "    loss = nn.MSELoss()\n",
    "    if out_func == 'feas':\n",
    "        loss = loss(out, feas)\n",
    "    elif out_func == 'obj':\n",
    "        loss = loss(out, c.T @ sol)\n",
    "    else:\n",
    "        loss = loss(out, sol)\n",
    "    return loss\n",
    "\n",
    "\n",
    "for batch in data_test:\n",
    "    c, A, b, constraints, l, u, sol, feas = batch\n",
    "    c = c.to(device)\n",
    "    A = A.to(device)\n",
    "    b = b.to(device)\n",
    "    constraints = constraints.to(device)\n",
    "    l = l.to(device)\n",
    "    u = u.to(device)\n",
    "    sol = sol.to(device)\n",
    "    feas = feas.to(device)\n",
    "\n",
    "    loss = test(model2, c, A, b, constraints, l, u, sol, feas, out_func)\n",
    "    print(f\"Loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
