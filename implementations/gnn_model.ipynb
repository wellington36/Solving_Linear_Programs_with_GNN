{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random as rd\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from model import LPGNN\n",
    "from generate_data import generate_random_linear_program, solve_linear_program, generate_and_solve_batches\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                   | 0/200 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "### PARAMETERS ###\n",
    "num_constraints = 2\n",
    "num_variables = 5\n",
    "batch_size = 10\n",
    "learning_rate = 0.003\n",
    "N = 100\n",
    "out_func = 'obj'\n",
    "\n",
    "device = device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = LPGNN(num_constraints, num_variables).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 200\n",
    "pbar = tqdm(range(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = []\n",
    "for i in range(N):\n",
    "    c, A, b, constraints, l, u, solution, feasibility = generate_and_solve_batches(batch_size,\n",
    "                                                                                   num_variables,\n",
    "                                                                                   num_constraints,\n",
    "                                                                                   out_func)\n",
    "    data_train.append([c, A, b, constraints, l, u, solution, feasibility])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, c, A, b, constraint, l, u, sol, feas, out_func, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(c, A, b, constraint, l, u, out_func)\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    if out_func == 'feas':\n",
    "        loss = loss(out, feas)\n",
    "\n",
    "    elif out_func == 'obj':\n",
    "        #loss = loss(out, (c[:, None, :] @ sol[:, :, None])[:,0])\n",
    "        loss = loss(out[:,0], torch.sum(c * sol, dim=1))\n",
    "\n",
    "    else:\n",
    "        loss = loss(out, sol)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Training model\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00105518: 100%|█████████████████████████████████████████████████████████████████████████████| 200/200 [13:49<00:00,  4.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "print(\"\\n\\n\")\n",
    "print(\"Training model\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    for batch in data_train:\n",
    "        c, A, b, constraints, l, u, sol, feas = batch\n",
    "        c = c.to(device)\n",
    "        A = A.to(device)\n",
    "        b = b.to(device)\n",
    "        constraints = constraints.to(device)\n",
    "        l = l.to(device)\n",
    "        u = u.to(device)\n",
    "        sol = sol.to(device)\n",
    "        feas = feas\n",
    "        loss = train(model, c, A, b, constraints, l, u, sol, feas, out_func, optimizer)\n",
    "        pbar.set_description(f\"%.8f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wellington/.local/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([5, 5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing model\n",
      "\n",
      "\n",
      "\n",
      "Loss: 0.03629964217543602\n",
      "Loss: 0.026638749986886978\n",
      "Loss: 0.021153492853045464\n",
      "Loss: 0.01904143951833248\n",
      "Loss: 0.027411531656980515\n",
      "Loss: 0.02739361859858036\n",
      "Loss: 0.037968821823596954\n",
      "Loss: 0.021481657400727272\n",
      "Loss: 0.0209252517670393\n",
      "Loss: 0.015586357563734055\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "print(\"\\n\\n\")\n",
    "print(\"Testing model\")\n",
    "print(\"\\n\\n\")\n",
    "batch_size = 5\n",
    "M = 10\n",
    "\n",
    "data_test = []\n",
    "for i in range(M):\n",
    "    c, A, b, constraints, l, u, solution, feasibility = generate_and_solve_batches(batch_size,\n",
    "                                                                                   num_variables,\n",
    "                                                                                   num_constraints,\n",
    "                                                                                   out_func)\n",
    "    data_test.append([c, A, b, constraints, l, u, solution, feasibility])\n",
    "\n",
    "def test(model, c, A, b, constraint, l, u, sol, feas, out_func):\n",
    "    out = model.forward(c, A, b, constraint, l, u, out_func)\n",
    "    loss = nn.MSELoss()\n",
    "    if out_func == 'feas':\n",
    "        loss = loss(out, feas)\n",
    "    elif out_func == 'obj':\n",
    "        loss = loss(out, c.T @ sol)\n",
    "    else:\n",
    "        loss = loss(out, sol)\n",
    "    return loss\n",
    "\n",
    "\n",
    "for batch in data_test:\n",
    "    c, A, b, constraints, l, u, sol, feas = batch\n",
    "    c = c.to(device)\n",
    "    A = A.to(device)\n",
    "    b = b.to(device)\n",
    "    constraints = constraints.to(device)\n",
    "    l = l.to(device)\n",
    "    u = u.to(device)\n",
    "    sol = sol.to(device)\n",
    "    feas = feas.to(device)\n",
    "\n",
    "    loss = test(model, c, A, b, constraints, l, u, sol, feas, out_func)\n",
    "    print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Testing model\n",
      "\n",
      "\n",
      "\n",
      "Loss: 0.3098640441894531\n",
      "Loss: 0.4725342392921448\n",
      "Loss: 0.45849043130874634\n",
      "Loss: 0.45237258076667786\n",
      "Loss: 0.5035025477409363\n",
      "Loss: 0.43440669775009155\n",
      "Loss: 0.506040096282959\n",
      "Loss: 0.34443971514701843\n",
      "Loss: 0.3126998543739319\n",
      "Loss: 0.3500613272190094\n"
     ]
    }
   ],
   "source": [
    "model2 = LPGNN(num_constraints, num_variables).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# Test model\n",
    "print(\"\\n\\n\")\n",
    "print(\"Testing model\")\n",
    "print(\"\\n\\n\")\n",
    "batch_size = 5\n",
    "M = 10\n",
    "\n",
    "data_test = []\n",
    "for i in range(M):\n",
    "    c, A, b, constraints, l, u, solution, feasibility = generate_and_solve_batches(batch_size,\n",
    "                                                                                   num_variables,\n",
    "                                                                                   num_constraints,\n",
    "                                                                                   out_func)\n",
    "    data_test.append([c, A, b, constraints, l, u, solution, feasibility])\n",
    "\n",
    "def test(model, c, A, b, constraint, l, u, sol, feas, out_func):\n",
    "    out = model.forward(c, A, b, constraint, l, u, out_func)\n",
    "    loss = nn.MSELoss()\n",
    "    if out_func == 'feas':\n",
    "        loss = loss(out, feas)\n",
    "    elif out_func == 'obj':\n",
    "        loss = loss(out, c.T @ sol)\n",
    "    else:\n",
    "        loss = loss(out, sol)\n",
    "    return loss\n",
    "\n",
    "\n",
    "for batch in data_test:\n",
    "    c, A, b, constraints, l, u, sol, feas = batch\n",
    "    c = c.to(device)\n",
    "    A = A.to(device)\n",
    "    b = b.to(device)\n",
    "    constraints = constraints.to(device)\n",
    "    l = l.to(device)\n",
    "    u = u.to(device)\n",
    "    sol = sol.to(device)\n",
    "    feas = feas.to(device)\n",
    "\n",
    "    loss = test(model2, c, A, b, constraints, l, u, sol, feas, out_func)\n",
    "    print(f\"Loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
